{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is the MNIST dataset of handwritten digits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = mnist.train.images, mnist.train.labels, mnist.validation.images, mnist.validation.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize(x, y):\n",
    "    \"\"\" Randomizes the order of data samples and their corresponding labels\"\"\"\n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    shuffled_x = x[permutation, :]\n",
    "    shuffled_y = y[permutation]\n",
    "    return shuffled_x, shuffled_y\n",
    "\n",
    "def get_next_batch(x, y, start, end):\n",
    "    x_batch = x[start:end]\n",
    "    y_batch = y[start:end]\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "inputs = 28 # input image is 28 x 28  (cols)\n",
    "steps = 28 #  (rows)\n",
    "classes = 10 # we want to have 10 classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "learning_rate = 0.001 \n",
    "epochs = 10\n",
    "batch_size = 100 \n",
    "freq = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape): \n",
    "    initer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "    return tf.get_variable('W',dtype=tf.float32,shape=shape,initializer=initer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0., shape=shape, dtype=tf.float32)\n",
    "    return tf.get_variable('b',dtype=tf.float32,initializer=initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x,weights,biases, timesteps, hidden):\n",
    "    x = tf.unstack(x,timesteps,1)\n",
    "    rnn_cell = rnn.BasicRNNCell(hidden)\n",
    "    states_series, current_state = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "    return tf.matmul(current_state, weights)+biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, steps, inputs], name='X')\n",
    "y = tf.placeholder(tf.float32, shape=[None, classes], name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "W = weight_variable(shape=[hidden_units, classes])\n",
    "b = bias_variable(shape=[classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-f6eb28162fc7>:3: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-10-f6eb28162fc7>:4: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    }
   ],
   "source": [
    "output_logits = RNN(x,W,b, steps, hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(output_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-88cfb151bcdb>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model predictions\n",
    "cls_prediction = tf.argmax(output_logits, axis=1, name='predictions')\n",
    "\n",
    "# Define the loss function, optimizer, and accuracy\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output_logits), name='loss')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(output_logits, 1), tf.argmax(y, 1), name='correct_pred')\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "iter   0:\t Loss=2.28,\tTraining Accuracy=23.0%\n",
      "iter 100:\t Loss=0.94,\tTraining Accuracy=74.0%\n",
      "iter 200:\t Loss=0.61,\tTraining Accuracy=84.0%\n",
      "iter 300:\t Loss=0.56,\tTraining Accuracy=82.0%\n",
      "iter 400:\t Loss=0.48,\tTraining Accuracy=87.0%\n",
      "iter 500:\t Loss=0.36,\tTraining Accuracy=89.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 1, validation loss: 0.34, validation accuracy: 91.2%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 2\n",
      "iter   0:\t Loss=0.22,\tTraining Accuracy=96.0%\n",
      "iter 100:\t Loss=0.16,\tTraining Accuracy=94.0%\n",
      "iter 200:\t Loss=0.29,\tTraining Accuracy=93.0%\n",
      "iter 300:\t Loss=0.29,\tTraining Accuracy=92.0%\n",
      "iter 400:\t Loss=0.23,\tTraining Accuracy=95.0%\n",
      "iter 500:\t Loss=0.19,\tTraining Accuracy=92.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 2, validation loss: 0.32, validation accuracy: 91.6%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 3\n",
      "iter   0:\t Loss=0.17,\tTraining Accuracy=96.0%\n",
      "iter 100:\t Loss=0.22,\tTraining Accuracy=95.0%\n",
      "iter 200:\t Loss=0.17,\tTraining Accuracy=94.0%\n",
      "iter 300:\t Loss=0.29,\tTraining Accuracy=93.0%\n",
      "iter 400:\t Loss=0.25,\tTraining Accuracy=91.0%\n",
      "iter 500:\t Loss=0.16,\tTraining Accuracy=94.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 3, validation loss: 0.22, validation accuracy: 94.3%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 4\n",
      "iter   0:\t Loss=0.22,\tTraining Accuracy=93.0%\n",
      "iter 100:\t Loss=0.12,\tTraining Accuracy=96.0%\n",
      "iter 200:\t Loss=0.20,\tTraining Accuracy=97.0%\n",
      "iter 300:\t Loss=0.20,\tTraining Accuracy=95.0%\n",
      "iter 400:\t Loss=0.24,\tTraining Accuracy=95.0%\n",
      "iter 500:\t Loss=0.24,\tTraining Accuracy=94.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 4, validation loss: 0.20, validation accuracy: 94.7%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 5\n",
      "iter   0:\t Loss=0.23,\tTraining Accuracy=92.0%\n",
      "iter 100:\t Loss=0.21,\tTraining Accuracy=94.0%\n",
      "iter 200:\t Loss=0.07,\tTraining Accuracy=97.0%\n",
      "iter 300:\t Loss=0.22,\tTraining Accuracy=94.0%\n",
      "iter 400:\t Loss=0.15,\tTraining Accuracy=96.0%\n",
      "iter 500:\t Loss=0.15,\tTraining Accuracy=96.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 5, validation loss: 0.17, validation accuracy: 95.6%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 6\n",
      "iter   0:\t Loss=0.05,\tTraining Accuracy=98.0%\n",
      "iter 100:\t Loss=0.09,\tTraining Accuracy=98.0%\n",
      "iter 200:\t Loss=0.17,\tTraining Accuracy=98.0%\n",
      "iter 300:\t Loss=0.15,\tTraining Accuracy=94.0%\n",
      "iter 400:\t Loss=0.17,\tTraining Accuracy=96.0%\n",
      "iter 500:\t Loss=0.09,\tTraining Accuracy=97.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 6, validation loss: 0.16, validation accuracy: 96.0%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 7\n",
      "iter   0:\t Loss=0.11,\tTraining Accuracy=97.0%\n",
      "iter 100:\t Loss=0.10,\tTraining Accuracy=95.0%\n",
      "iter 200:\t Loss=0.04,\tTraining Accuracy=98.0%\n",
      "iter 300:\t Loss=0.05,\tTraining Accuracy=99.0%\n",
      "iter 400:\t Loss=0.12,\tTraining Accuracy=97.0%\n",
      "iter 500:\t Loss=0.08,\tTraining Accuracy=96.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 7, validation loss: 0.14, validation accuracy: 96.3%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 8\n",
      "iter   0:\t Loss=0.17,\tTraining Accuracy=96.0%\n",
      "iter 100:\t Loss=0.13,\tTraining Accuracy=95.0%\n",
      "iter 200:\t Loss=0.12,\tTraining Accuracy=95.0%\n",
      "iter 300:\t Loss=0.04,\tTraining Accuracy=100.0%\n",
      "iter 400:\t Loss=0.11,\tTraining Accuracy=98.0%\n",
      "iter 500:\t Loss=0.11,\tTraining Accuracy=96.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 8, validation loss: 0.15, validation accuracy: 95.8%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 9\n",
      "iter   0:\t Loss=0.06,\tTraining Accuracy=97.0%\n",
      "iter 100:\t Loss=0.19,\tTraining Accuracy=97.0%\n",
      "iter 200:\t Loss=0.03,\tTraining Accuracy=100.0%\n",
      "iter 300:\t Loss=0.06,\tTraining Accuracy=99.0%\n",
      "iter 400:\t Loss=0.19,\tTraining Accuracy=94.0%\n",
      "iter 500:\t Loss=0.06,\tTraining Accuracy=99.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 9, validation loss: 0.13, validation accuracy: 96.3%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 10\n",
      "iter   0:\t Loss=0.04,\tTraining Accuracy=100.0%\n",
      "iter 100:\t Loss=0.10,\tTraining Accuracy=98.0%\n",
      "iter 200:\t Loss=0.06,\tTraining Accuracy=98.0%\n",
      "iter 300:\t Loss=0.04,\tTraining Accuracy=98.0%\n",
      "iter 400:\t Loss=0.02,\tTraining Accuracy=99.0%\n",
      "iter 500:\t Loss=0.08,\tTraining Accuracy=97.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 10, validation loss: 0.12, validation accuracy: 96.7%\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "global_step = 0\n",
    "# Number of training iterations in each epoch\n",
    "num_tr_iter = int(len(y_train) / batch_size)\n",
    "for epoch in range(epochs):\n",
    "    print('Training epoch: {}'.format(epoch + 1))\n",
    "    x_train, y_train = randomize(x_train, y_train)\n",
    "    for iteration in range(num_tr_iter):\n",
    "        global_step += 1\n",
    "        start = iteration * batch_size\n",
    "        end = (iteration + 1) * batch_size\n",
    "        x_batch, y_batch = get_next_batch(x_train, y_train, start, end)\n",
    "        x_batch = x_batch.reshape((batch_size, steps, inputs))\n",
    "        # Run optimization op (backprop)\n",
    "        feed_dict_batch = {x: x_batch, y: y_batch}\n",
    "        sess.run(optimizer, feed_dict=feed_dict_batch)\n",
    "\n",
    "        if iteration % freq == 0:\n",
    "            # Calculate and display the batch loss and accuracy\n",
    "            loss_batch, acc_batch = sess.run([loss, accuracy],\n",
    "                                             feed_dict=feed_dict_batch)\n",
    "\n",
    "            print(\"iter {0:3d}:\\t Loss={1:.2f},\\tTraining Accuracy={2:.01%}\".\n",
    "                  format(iteration, loss_batch, acc_batch))\n",
    "\n",
    "    # Run validation after every epoch\n",
    "\n",
    "    feed_dict_valid = {x: x_valid[:1000].reshape((-1, steps, inputs)), y: y_valid[:1000]}\n",
    "    loss_valid, acc_valid = sess.run([loss, accuracy], feed_dict=feed_dict_valid)\n",
    "    print('---------------------------------------------------------')\n",
    "    print(\"Epoch: {0}, validation loss: {1:.2f}, validation accuracy: {2:.01%}\".\n",
    "          format(epoch + 1, loss_valid, acc_valid))\n",
    "    print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None, title=None):\n",
    "    \"\"\"\n",
    "    Create figure with 3x3 sub-plots.\n",
    "    :param images: array of images to be plotted, (9, img_h*img_w)\n",
    "    :param cls_true: corresponding true labels (9,)\n",
    "    :param cls_pred: corresponding true labels (9,)\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(9, 9))\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(np.squeeze(images[i]).reshape(28, 28), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            ax_title = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            ax_title = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_title(ax_title)\n",
    "\n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    if title:\n",
    "        plt.suptitle(title, size=20)\n",
    "    plt.show(block=False)\n",
    "\n",
    "def plot_example_errors(images, cls_true, cls_pred, title=None):\n",
    "    \"\"\"\n",
    "    Function for plotting examples of images that have been mis-classified\n",
    "    :param images: array of all images, (#imgs, img_h*img_w)\n",
    "    :param cls_true: corresponding true labels, (#imgs,)\n",
    "    :param cls_pred: corresponding predicted labels, (#imgs,)\n",
    "    \"\"\"\n",
    "    # Negate the boolean array.\n",
    "    incorrect = np.logical_not(np.equal(cls_pred, cls_true))\n",
    "\n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    incorrect_images = images[incorrect]\n",
    "\n",
    "    # Get the true and predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "    cls_true = cls_true[incorrect]\n",
    "\n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=incorrect_images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9],\n",
    "                title=title)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a8826ea2e3ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test the network (only on 1000 samples) after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfeed_dict_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the network (only on 1000 samples) after training\n",
    "# Accuracy\n",
    "x_test, y_test = mnist.test.images, mnist.test.labels\n",
    "feed_dict_test = {x: x_test[:1000].reshape((-1, timesteps, num_input)), y: y_test[:1000]}\n",
    "loss_test, acc_test = sess.run([loss, accuracy], feed_dict=feed_dict_test)\n",
    "print('---------------------------------------------------------')\n",
    "print(\"Test loss: {0:.2f}, test accuracy: {1:.01%}\".format(loss_test, acc_test))\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Plot some of the correct and misclassified examples\n",
    "cls_pred = sess.run(cls_prediction, feed_dict=feed_dict_test)\n",
    "cls_true = np.argmax(y_test, axis=1)\n",
    "plot_images(x_test, cls_true, cls_pred, title='Correct Examples')\n",
    "plot_example_errors(x_test[:1000], cls_true[:1000], cls_pred, title='Misclassified Examples')\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
